{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Exercise 8\n",
    "'''\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt #define shorthand \"plt\" for package matlobplit.pyplot\n",
    "import numpy as np #define shorthand \"np\" for the numpy package\n",
    "import scipy.stats as sci\n",
    "import math as mat\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from IPython.display import Markdown as md\n",
    "import pystan\n",
    "from psis import psisloo\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 8\n",
    "Six factory machines' quality measurements STAN code is presented below for the separate, pooled and hierarchical models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pystan:COMPILING THE C++ CODE FOR MODEL anon_model_1bfc4e9af8e67e9dc3cef8d227a9abeb NOW.\n"
     ]
    }
   ],
   "source": [
    "#Separate STAN model\n",
    "\n",
    "factory_separate_stan_code=\"\"\"\n",
    "data {\n",
    "    int<lower=0> N; // number of data points\n",
    "    int<lower=0> K; // number of groups\n",
    "    int<lower=1,upper=K> x[N]; // group indicator\n",
    "    vector[N] y; //\n",
    "}\n",
    "parameters {\n",
    "    vector[K] mu;         // group means\n",
    "    vector<lower=0>[K] sigma;  // std's of the groups\n",
    "}\n",
    "model {\n",
    "  y ~ normal(mu[x], sigma[x]);\n",
    "}\n",
    "generated quantities {\n",
    "    real ypred6;\n",
    "    vector[N] log_lik;\n",
    "    ypred6 = normal_rng(mu[6], sigma[6]);  \n",
    "    for (i in 1:N)\n",
    "        log_lik[i] = normal_lpdf(y[i] | mu[x[i]], sigma[x[i]]);    \n",
    "}\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "sm_factory_separate = pystan.StanModel(model_code=factory_separate_stan_code)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pystan:COMPILING THE C++ CODE FOR MODEL anon_model_3f30e1cbe8094112c8b53d4af99ea40e NOW.\n"
     ]
    }
   ],
   "source": [
    "#Pooled STAN model\n",
    "\n",
    "factory_pooled_stan_code=\"\"\"\n",
    "data {\n",
    "    int<lower=0> N; // number of data points\n",
    "    vector[N] y; //\n",
    "}\n",
    "parameters {\n",
    "    real mu;               // prior mean\n",
    "    real<lower=0> sigma;   // prior std\n",
    "}\n",
    "model {\n",
    "  y ~ normal(mu, sigma);\n",
    "}\n",
    "generated quantities {\n",
    "    real ypred6;\n",
    "    vector[N] log_lik;\n",
    "    ypred6 = normal_rng(mu, sigma);\n",
    "    for (i in 1:N)\n",
    "        log_lik[i] = normal_lpdf(y[i] | mu, sigma);   \n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "sm_factory_pooled = pystan.StanModel(model_code=factory_pooled_stan_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pystan:COMPILING THE C++ CODE FOR MODEL anon_model_2a8be7fc9197f4f28ab0b72237d8679c NOW.\n"
     ]
    }
   ],
   "source": [
    "# Hierarchical STAN model\n",
    "\n",
    "factory_hierarchical_stan_code=\"\"\"\n",
    "data {\n",
    "    int<lower=0> N; // number of data points\n",
    "    int<lower=0> K; // number of groups\n",
    "    int<lower=1,upper=K> x[N]; // group indicator\n",
    "    vector[N] y; //\n",
    "}\n",
    "parameters {\n",
    "    real mu0;             // prior mean\n",
    "    real<lower=0> sigma0; // prior std\n",
    "    vector[K] mu;         // group means\n",
    "    real<lower=0> sigma;  // common std\n",
    "}\n",
    "model {\n",
    "    mu ~ normal(mu0, sigma0); // population prior with unknown parameters\n",
    "    y ~ normal(mu[x], sigma);\n",
    "}\n",
    "generated quantities {\n",
    "    real ypred6;\n",
    "    real mu7;\n",
    "    vector[N] log_lik;\n",
    "    ypred6 = normal_rng(mu[6], sigma);\n",
    "    mu7 = normal_rng(mu0, sigma0);\n",
    "    for (i in 1:N)\n",
    "        log_lik[i] = normal_lpdf(y[i] | mu[x[i]], sigma);     \n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "sm_factory_hierarchical = pystan.StanModel(model_code=factory_hierarchical_stan_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create the data for the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=np.array(([83 ,117, 101, 105, 79, 57],\n",
    "[92, 109, 93, 119, 97, 92],\n",
    "[92, 114, 92, 116, 103, 104],\n",
    "[46, 104, 86, 102, 79, 77],\n",
    "[67, 87, 67, 116, 92, 100]  ))\n",
    "\n",
    "y=np.reshape(y, 30, order='F')\n",
    "x=np.concatenate( (np.ones(5) , 2*np.ones(5) ,  3*np.ones(5),\n",
    "                   4*np.ones(5),5*np.ones(5),6*np.ones(5)) ).astype(int)\n",
    "\n",
    "factory_separate_dat = {'y':y,\n",
    "                            'x': x,\n",
    "                            'N': 30,\n",
    "                            'K': 6\n",
    "                           }\n",
    "\n",
    "factory_pooled_dat = {'y':y,\n",
    "                      'N': 30,\n",
    "                      }\n",
    "factory_hierarchical_dat = {'y':y,\n",
    "                           'x': x,\n",
    "                           'N': 30,\n",
    "                           'K': 6\n",
    "                           }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separate model \n",
    "In the separate model each machine $j$ has its own mean $\\mu_j$ and standard deviation $\\sigma_j$. This makes total of 12 parameters to be approximated.\n",
    "\n",
    "The PSIS-LOO value is -132.146, which is the highest of the three models. The smaller the number the better the model is considered to be if the PSIS-LOO value can be considered stable. This model is the worst of the three based on the PSIS-LOO value.\n",
    "\n",
    "The effective number of parameters $p_{eff}=p_{loo-cv}$ is 9.530012698216112 which means that out of the 12 parameters estimated 9,5 are considered to be effective.\n",
    "\n",
    "The calculated $\\hat{k}$ values of PSIS_LOO values for the observatios with the Separate model are presented in the histogram below. There are 4 of the $\\hat{k}$ values that are over > 0.7 so the estimate is probably little bit biased. This is means that the PSIS-LOO value is not completely accurate. There should be used some more accurate and computationally more expensive methods to evaluate LOO value for the 4 observations in question to get a more accurate estimate. However it can be said that the value quite clearly is worse than the other two.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PSIS-LOO value: -132.14664228183975\n",
      "p_loocv effective number of parameters: 9.530012698216112\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference for Stan model: anon_model_1bfc4e9af8e67e9dc3cef8d227a9abeb.\n",
      "4 chains, each with iter=2000; warmup=1000; thin=1; \n",
      "post-warmup draws per chain=1000, total post-warmup draws=4000.\n",
      "\n",
      "              mean se_mean     sd   2.5%    25%    50%    75%  97.5%  n_eff   Rhat\n",
      "mu[1]        75.83    0.49  16.06  45.01  68.42  76.02  83.34 104.71   1094    1.0\n",
      "mu[2]       106.14    0.24   9.66  86.91  101.5 106.18 110.77 125.92   1588    1.0\n",
      "mu[3]        88.13    0.37  11.09  68.14  82.75  87.89  93.14 110.97    907   1.01\n",
      "mu[4]        111.8    0.18   6.47  98.94  108.7 111.78 114.87 125.08   1311    1.0\n",
      "mu[5]        90.44    0.27   8.73  73.89  85.85  90.21  94.59 108.57   1067    1.0\n",
      "mu[6]        86.13    0.46  16.55  55.23   77.9  85.66  93.88 121.25   1289    1.0\n",
      "sigma[1]     31.11    0.76  24.61  12.83  19.32  25.44  35.26   79.7   1060    1.0\n",
      "sigma[2]     18.69    0.33  11.98   7.68  11.65  15.28  21.27   50.2   1290    1.0\n",
      "sigma[3]     20.71    0.53  14.38   8.37  12.65  16.58  23.54  59.27    744    1.0\n",
      "sigma[4]     12.02    0.24   8.45   5.08   7.48   9.78  13.66   32.4   1208    1.0\n",
      "sigma[5]     17.17     0.4  12.25   7.04  10.59  13.89  19.68  45.19    958    1.0\n",
      "sigma[6]      31.1    0.69  22.33  12.38  19.07  25.45  35.69  82.16   1049    1.0\n",
      "ypred6       86.04    0.73  38.96   8.38   66.6  85.93 104.21 163.69   2843    1.0\n",
      "log_lik[1]   -4.36    0.01   0.49  -5.46  -4.63  -4.31  -4.02  -3.61   1110    1.0\n",
      "log_lik[2]   -4.57    0.01   0.47  -5.68  -4.83   -4.5  -4.24  -3.84   1300    1.0\n",
      "log_lik[3]   -4.57    0.01   0.47  -5.68  -4.83   -4.5  -4.24  -3.84   1300    1.0\n",
      "log_lik[4]   -5.18    0.01   0.71  -7.02  -5.48  -5.05  -4.71  -4.24   3810    1.0\n",
      "log_lik[5]   -4.39    0.01   0.48  -5.45  -4.66  -4.33  -4.06  -3.64   1184    1.0\n",
      "log_lik[6]   -4.13    0.01   0.47  -5.19  -4.41  -4.06  -3.79  -3.37   1620    1.0\n",
      "log_lik[7]   -3.83    0.01   0.49  -4.99  -4.11  -3.77  -3.48  -3.06   1158    1.0\n",
      "log_lik[8]   -3.98    0.01   0.47  -5.09  -4.24  -3.91  -3.64  -3.23   1324    1.0\n",
      "log_lik[9]   -3.82    0.01    0.5  -4.99  -4.09  -3.77  -3.47  -3.05   1151    1.0\n",
      "log_lik[10]   -4.8    0.01   0.78  -6.86  -5.13  -4.64  -4.28   -3.8   4152    1.0\n",
      "log_lik[11]   -4.3    0.01   0.51  -5.53  -4.57  -4.23  -3.94  -3.53   1751    1.0\n",
      "log_lik[12]  -3.97    0.02    0.5  -5.15  -4.24  -3.91  -3.61  -3.17    980    1.0\n",
      "log_lik[13]  -3.95    0.02   0.51  -5.15  -4.22  -3.89  -3.59  -3.15    958    1.0\n",
      "log_lik[14]  -3.92    0.02   0.52  -5.16  -4.21  -3.85  -3.55  -3.11    900    1.0\n",
      "log_lik[15]   -4.9    0.01   0.81  -7.07  -5.24  -4.73  -4.35  -3.86   4371    1.0\n",
      "log_lik[16]  -3.66    0.01   0.49  -4.83  -3.95   -3.6  -3.31  -2.88   1598    1.0\n",
      "log_lik[17]  -3.73    0.01   0.49  -4.89   -4.0  -3.66  -3.37  -2.96   1511    1.0\n",
      "log_lik[18]   -3.5    0.01   0.48  -4.63  -3.76  -3.42  -3.16  -2.75   1110    1.0\n",
      "log_lik[19]  -3.98    0.01   0.59  -5.35  -4.28   -3.9  -3.58  -3.13   2948    1.0\n",
      "log_lik[20]   -3.5    0.01   0.48  -4.63  -3.76  -3.42  -3.16  -2.75   1110    1.0\n",
      "log_lik[21]  -4.12    0.01    0.5  -5.27   -4.4  -4.07  -3.76  -3.32   1691    1.0\n",
      "log_lik[22]  -3.88    0.01   0.47  -4.98  -4.15  -3.82  -3.54  -3.13   1185    1.0\n",
      "log_lik[23]  -4.27    0.01   0.55  -5.59  -4.56  -4.19  -3.89  -3.45   2637    1.0\n",
      "log_lik[24]  -4.12    0.01    0.5  -5.27   -4.4  -4.07  -3.76  -3.32   1691    1.0\n",
      "log_lik[25]  -3.73    0.02    0.5  -4.87  -4.02  -3.66  -3.38  -2.95   1054    1.0\n",
      "log_lik[26]  -5.14    0.01   0.71  -6.95  -5.45   -5.0  -4.67  -4.19   4014    1.0\n",
      "log_lik[27]  -4.36    0.01   0.49  -5.46  -4.65   -4.3  -4.01  -3.58   1111    1.0\n",
      "log_lik[28]  -4.66    0.01   0.49  -5.77  -4.93   -4.6  -4.32  -3.87   1653    1.0\n",
      "log_lik[29]   -4.4    0.01    0.5  -5.53  -4.69  -4.34  -4.04   -3.6   1156    1.0\n",
      "log_lik[30]  -4.53    0.01   0.48  -5.59  -4.81  -4.47   -4.2  -3.75   1312    1.0\n",
      "lp__        -81.34    0.11   3.15  -88.6 -83.22 -80.97 -79.06  -76.4    761    1.0\n",
      "\n",
      "Samples were drawn using NUTS at Sat Nov 17 22:45:00 2018.\n",
      "For each parameter, n_eff is a crude measure of effective sample size,\n",
      "and Rhat is the potential scale reduction factor on split chains (at \n",
      "convergence, Rhat=1).\n"
     ]
    }
   ],
   "source": [
    "#Separate\n",
    "\n",
    "fit_separate = sm_factory_separate.sampling(data=factory_separate_dat, n_jobs=-1)\n",
    "ypred6_separate=fit_separate.extract(permuted=True)['ypred6']\n",
    "mu_separate=fit_separate.extract(permuted=True)['mu']\n",
    "log_lik=fit_separate.extract(permuted=True)['log_lik']\n",
    "psis=psisloo(log_lik)\n",
    "print(\"PSIS-LOO value:\", psis[0])\n",
    "#Estimate of the effective number of parameters\n",
    "#lppd (computd log pointwise predictive density) calculation\n",
    "S=np.size(log_lik,0)\n",
    "lppd=sum(np.log([1/S*sum(np.exp(col)) for col in log_lik.T]))\n",
    "#Formula: p_loocv=lppd-lppd_loocv\n",
    "p_loocv=lppd-psis[0]\n",
    "print(\"p_loocv effective number of parameters:\",p_loocv)\n",
    "plt.hist(psis[2], bins=np.linspace(0,1,11))\n",
    "plt.title(\"$\\^{k}$ of PSIS-LOO for the observations with separate model N=4000\")\n",
    "plt.show()\n",
    "\n",
    "summary_separate=fit_separate.summary()\n",
    "summary_df_separate=pd.DataFrame(summary_separate['summary'], \n",
    "                                 columns=summary_separate['summary_colnames'], \n",
    "                                 index=summary_separate['summary_rownames'])\n",
    "\n",
    "#Print info on the fitting and sampling of paramters alpha and beta \n",
    "print(fit_separate)\n",
    "#fit_separate.plot()\n",
    "#plt.show()\n",
    "\n",
    "#plt.hist(mu_separate[:,5],bins=50)\n",
    "#plt.title(\"Posterior mean of machine 6\")\n",
    "#plt.show()\n",
    "#plt.hist(ypred6_separate, bins=50)\n",
    "#plt.title(\"Predictive distribution of quality measurement for machine 6\")\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pooled model \n",
    "In the pooled model all the data of the machines are assumed to be from one machine in theoretically speaking. All the machines have thus same mean $\\mu$ and standard deviation $\\sigma$. This way there are only two parameters in the model to estimate.\n",
    "\n",
    "The PSIS-LOO value is -130.99, which is the middle value for the three models. The smaller the number the better the model is considered to be if the PSIS-LOO value can be considered stable. This is between the separate and the hierarchical models in goodness-of-fit.\n",
    "\n",
    "The effective number of parameters $p_{eff}=p_{loo-cv}$ is 2.02 which means that the 2 parameters are considered quite effective for the model.\n",
    "\n",
    "The calculated $\\hat{k}$ values of PSIS_LOO values for the observatios with the Pooled model are presented in the histogram below. All the $\\hat{k}$ values are under < 0.7, so the PSIS-LOO estimate can be considered to be good approximation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PSIS-LOO value: -130.99238195225863\n",
      "p_loocv effective number of parameters: 2.015749266322473\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference for Stan model: anon_model_3f30e1cbe8094112c8b53d4af99ea40e.\n",
      "4 chains, each with iter=2000; warmup=1000; thin=1; \n",
      "post-warmup draws per chain=1000, total post-warmup draws=4000.\n",
      "\n",
      "              mean se_mean     sd   2.5%    25%    50%    75%  97.5%  n_eff   Rhat\n",
      "mu           92.93    0.06   3.42  86.21  90.67  92.89  95.15   99.9   2769    1.0\n",
      "sigma        18.86    0.05   2.65  14.47  16.97  18.56  20.44  24.84   2504    1.0\n",
      "ypred6       92.52    0.31   19.4  53.47  79.58  92.91 105.25  131.1   4040    1.0\n",
      "log_lik[1]   -4.01  2.9e-3   0.14  -4.32   -4.1   -4.0  -3.91  -3.74   2532    1.0\n",
      "log_lik[2]   -3.86  2.8e-3   0.14  -4.16  -3.95  -3.86  -3.77  -3.61   2411    1.0\n",
      "log_lik[3]   -3.86  2.8e-3   0.14  -4.16  -3.95  -3.86  -3.77  -3.61   2411    1.0\n",
      "log_lik[4]   -7.13    0.02   0.87  -9.12  -7.66  -7.03   -6.5  -5.72   2976    1.0\n",
      "log_lik[5]   -4.86  5.1e-3   0.29  -5.54  -5.02  -4.82  -4.65  -4.39   3143    1.0\n",
      "log_lik[6]   -4.73  4.8e-3   0.26  -5.32  -4.88   -4.7  -4.54  -4.29   3008    1.0\n",
      "log_lik[7]   -4.25  3.0e-3   0.16   -4.6  -4.35  -4.24  -4.14  -3.96   2984    1.0\n",
      "log_lik[8]   -4.53  3.9e-3   0.22   -5.0  -4.64  -4.51  -4.38  -4.16   3038    1.0\n",
      "log_lik[9]   -4.05  2.6e-3   0.14  -4.34  -4.13  -4.04  -3.95  -3.79   2755    1.0\n",
      "log_lik[10]  -3.91  2.9e-3   0.14  -4.21   -4.0  -3.91  -3.82  -3.66   2430    1.0\n",
      "log_lik[11]  -3.96  2.7e-3   0.14  -4.24  -4.05  -3.96  -3.87  -3.71   2610    1.0\n",
      "log_lik[12]  -3.86  2.8e-3   0.14  -4.16  -3.95  -3.86  -3.77  -3.61   2418    1.0\n",
      "log_lik[13]  -3.86  2.8e-3   0.14  -4.16  -3.95  -3.86  -3.77  -3.61   2411    1.0\n",
      "log_lik[14]  -3.93  2.9e-3   0.14  -4.23  -4.02  -3.93  -3.83  -3.67   2447    1.0\n",
      "log_lik[15]  -4.86  5.1e-3   0.29  -5.54  -5.02  -4.82  -4.65  -4.39   3143    1.0\n",
      "log_lik[16]  -4.08  2.7e-3   0.14  -4.38  -4.17  -4.08  -3.98  -3.82   2807    1.0\n",
      "log_lik[17]  -4.88  5.5e-3    0.3  -5.56  -5.05  -4.84  -4.67  -4.38   2981    1.0\n",
      "log_lik[18]  -4.66  4.5e-3   0.25  -5.21  -4.79  -4.63  -4.48  -4.25   3020    1.0\n",
      "log_lik[19]  -3.99  2.6e-3   0.14  -4.26  -4.07  -3.98  -3.89  -3.74   2655    1.0\n",
      "log_lik[20]  -4.66  4.5e-3   0.25  -5.21  -4.79  -4.63  -4.48  -4.25   3020    1.0\n",
      "log_lik[21]  -4.15  3.0e-3   0.15  -4.49  -4.25  -4.14  -4.04  -3.87   2729    1.0\n",
      "log_lik[22]  -3.89  2.8e-3   0.14  -4.18  -3.98  -3.88  -3.79  -3.63   2481    1.0\n",
      "log_lik[23]  -4.01  2.6e-3   0.14   -4.3   -4.1  -4.01  -3.92  -3.76   2703    1.0\n",
      "log_lik[24]  -4.15  3.0e-3   0.15  -4.49  -4.25  -4.14  -4.04  -3.87   2729    1.0\n",
      "log_lik[25]  -3.86  2.8e-3   0.14  -4.16  -3.95  -3.86  -3.77  -3.61   2411    1.0\n",
      "log_lik[26]  -5.78  9.3e-3   0.52  -6.99  -6.09  -5.71  -5.41  -4.95   3066    1.0\n",
      "log_lik[27]  -3.86  2.8e-3   0.14  -4.16  -3.95  -3.86  -3.77  -3.61   2411    1.0\n",
      "log_lik[28]  -4.05  2.6e-3   0.14  -4.34  -4.13  -4.04  -3.95  -3.79   2755    1.0\n",
      "log_lik[29]  -4.24  3.1e-3   0.17   -4.6  -4.34  -4.22  -4.12  -3.95   2847    1.0\n",
      "log_lik[30]  -3.94  2.7e-3   0.14  -4.22  -4.03  -3.93  -3.84  -3.68   2571    1.0\n",
      "lp__        -99.36    0.03   1.04 -102.1 -99.75 -99.03 -98.61 -98.35   1673    1.0\n",
      "\n",
      "Samples were drawn using NUTS at Sat Nov 17 23:10:39 2018.\n",
      "For each parameter, n_eff is a crude measure of effective sample size,\n",
      "and Rhat is the potential scale reduction factor on split chains (at \n",
      "convergence, Rhat=1).\n"
     ]
    }
   ],
   "source": [
    "# Pooled\n",
    "\n",
    "fit_pooled = sm_factory_pooled.sampling(data=factory_pooled_dat, n_jobs=-1)\n",
    "#mu7_pooled=fit_pooled.extract(permuted=True)['y7']\n",
    "ypred6_pooled=fit_pooled.extract(permuted=True)['ypred6']\n",
    "mu_pooled=fit_pooled.extract(permuted=True)['mu']\n",
    "mu7_pooled=mu_pooled\n",
    "log_lik=fit_pooled.extract(permuted=True)['log_lik']\n",
    "psis=psisloo(log_lik)\n",
    "print(\"PSIS-LOO value:\", psis[0])\n",
    "#Estimate of the effective number of parameters\n",
    "#lppd (computd log pointwise predictive density) calculation\n",
    "S=np.size(log_lik,0)\n",
    "lppd=sum(np.log([1/S*sum(np.exp(col)) for col in log_lik.T]))\n",
    "#Formula: p_loocv=lppd-lppd_loocv\n",
    "p_loocv=lppd-psis[0]\n",
    "print(\"p_loocv effective number of parameters:\",p_loocv)\n",
    "plt.hist(psis[2],bins=np.linspace(0,1,11))\n",
    "plt.title(\"$\\^{k}$ of PSIS-LOO for the observations with pooled model N=4000\")\n",
    "plt.show()\n",
    "\n",
    "summary_pooled=fit_pooled.summary()\n",
    "summary_df_pooled=pd.DataFrame(summary_pooled['summary'], \n",
    "                               columns=summary_pooled['summary_colnames'], \n",
    "                               index=summary_pooled['summary_rownames'])\n",
    "#Print info on the fitting and sampling of paramters alpha and beta \n",
    "print(fit_pooled)\n",
    "#fit_pooled.plot()\n",
    "#plt.show()\n",
    "\n",
    "#plt.hist(mu_pooled,bins=50)\n",
    "#plt.title(\"Posterior mean of machine 6\")\n",
    "#plt.show()\n",
    "#plt.hist(ypred6_pooled, bins=50)\n",
    "#plt.title(\"Predictive distribution of quality measurement for machine 6\")\n",
    "#plt.show()\n",
    "#plt.hist(mu7_pooled, bins=50)\n",
    "#plt.title(\"Posterior distribution of mean of quality measurement for machine 7\\n Posterior mean is the same for all the machines for Pooled model\")\n",
    "#plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hierarchical model \n",
    "In the hierarchical model $\\mu_0$ and $\\sigma_0$ were set as parameters for the prior distrubution mu $\\mu \\sim N( \\mu_0 , \\sigma_0 )$ for all machines where prior distribution for $\\mu_0$ and $\\sigma_0$ is assumed to be uniform. The standard deviation of quality measurements of all the machines was assumed to be equal for all machines. In total there are 9 parameters to be estimated.\n",
    "\n",
    "The PSIS-LOO value is -126.83, which is the smallest value for the three models. The smaller the number the better the model is considered to be if the PSIS-LOO value can be considered stable. So this model can be considered to be **the best** of the three.\n",
    "\n",
    "The effective number of parameters $p_{eff}=p_{loo-cv}$ is 5.73 which means that out of the 9 parameters 5.73 are considered quite effective for the model.\n",
    "\n",
    "The calculated $\\hat{k}$ values of PSIS_LOO values for the observatios with the Pooled model are presented in the histogram below. All the $\\hat{k}$ values are under < 0.7, so the PSIS-LOO estimate can be considered to be good.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pystan:21 of 4000 iterations ended with a divergence (0.525%).\n",
      "WARNING:pystan:Try running with adapt_delta larger than 0.8 to remove the divergences.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PSIS-LOO value: -126.83042187252312\n",
      "p_loo-cv estimated effective number of parameters: 5.726957568402469\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference for Stan model: anon_model_2a8be7fc9197f4f28ab0b72237d8679c.\n",
      "4 chains, each with iter=2000; warmup=1000; thin=1; \n",
      "post-warmup draws per chain=1000, total post-warmup draws=4000.\n",
      "\n",
      "              mean se_mean     sd   2.5%    25%    50%    75%  97.5%  n_eff   Rhat\n",
      "mu0          92.83    0.19   8.14  76.38  88.37  92.85  97.17 109.41   1756    1.0\n",
      "sigma0       16.52    0.28  10.45    4.8  10.28  14.16  19.62  43.12   1350    1.0\n",
      "mu[1]        79.76    0.16   6.84  66.23  75.42  79.75  84.26  93.38   1935    1.0\n",
      "mu[2]       103.01    0.13   6.65  89.53  98.55 103.11 107.44 115.78   2512    1.0\n",
      "mu[3]        88.79    0.11   6.07  76.46   84.7  88.96  92.75 100.55   3167    1.0\n",
      "mu[4]       107.44    0.15   6.78  93.72 102.95 107.58 111.95 120.46   1916   1.01\n",
      "mu[5]        90.81     0.1   6.12  78.72  86.75  90.92  94.89 102.66   3463    1.0\n",
      "mu[6]        87.37    0.11   6.27  74.75  83.26  87.57  91.53  99.47   3371    1.0\n",
      "sigma        15.23    0.05   2.38  11.29  13.57  15.03  16.67  20.67   2350    1.0\n",
      "ypred6       87.15    0.25  16.36  55.11  76.44  87.26  97.58 119.72   4123    1.0\n",
      "mu7          93.05    0.37  21.31  51.76  82.99  92.83 102.49 136.16   3270    1.0\n",
      "log_lik[1]   -3.76  4.8e-3   0.23  -4.28  -3.86  -3.73  -3.61  -3.41   2317    1.0\n",
      "log_lik[2]   -4.09  7.5e-3   0.42  -5.19  -4.26   -4.0  -3.81  -3.57   3114    1.0\n",
      "log_lik[3]   -4.09  7.5e-3   0.42  -5.19  -4.26   -4.0  -3.81  -3.57   3114    1.0\n",
      "log_lik[4]   -6.31    0.02    1.1  -8.75  -6.98  -6.19  -5.53  -4.51   3141    1.0\n",
      "log_lik[5]   -4.09 10.0e-3    0.4  -5.04   -4.3  -4.02  -3.81  -3.52   1590    1.0\n",
      "log_lik[6]   -4.16  8.1e-3   0.43  -5.22  -4.39  -4.08  -3.85  -3.55   2824    1.0\n",
      "log_lik[7]    -3.8  5.7e-3   0.26  -4.44  -3.93  -3.76  -3.63  -3.41   2045    1.0\n",
      "log_lik[8]   -3.99  7.1e-3   0.36  -4.87  -4.18  -3.93  -3.74  -3.48   2497    1.0\n",
      "log_lik[9]   -3.73  4.6e-3    0.2  -4.18  -3.84  -3.71  -3.59  -3.39   1924    1.0\n",
      "log_lik[10]  -4.34  9.4e-3   0.52  -5.62  -4.59  -4.23  -3.96  -3.67   3049    1.0\n",
      "log_lik[11]  -4.06  6.3e-3   0.37  -4.98  -4.24  -3.98  -3.81  -3.56   3379    1.0\n",
      "log_lik[12]  -3.75  4.1e-3   0.21  -4.26  -3.87  -3.73  -3.61   -3.4   2764    1.0\n",
      "log_lik[13]  -3.74  4.0e-3    0.2   -4.2  -3.85  -3.72   -3.6  -3.39   2629    1.0\n",
      "log_lik[14]  -3.73  4.0e-3   0.19  -4.17  -3.84  -3.71  -3.59   -3.4   2349    1.0\n",
      "log_lik[15]   -4.8  9.8e-3   0.63  -6.25  -5.16  -4.72  -4.34  -3.86   4058    1.0\n",
      "log_lik[16]  -3.75  4.2e-3   0.21  -4.23  -3.85  -3.72  -3.61  -3.41   2414    1.0\n",
      "log_lik[17]  -4.02  9.5e-3   0.37  -4.95  -4.22  -3.94  -3.75  -3.49   1559   1.01\n",
      "log_lik[18]  -3.88  8.6e-3   0.31  -4.65  -4.04  -3.82  -3.67  -3.43   1299   1.01\n",
      "log_lik[19]  -3.81  4.5e-3   0.24  -4.41  -3.92  -3.77  -3.65  -3.45   2954    1.0\n",
      "log_lik[20]  -3.88  8.6e-3   0.31  -4.65  -4.04  -3.82  -3.67  -3.43   1299   1.01\n",
      "log_lik[21]  -4.03  5.9e-3   0.34  -4.85  -4.22  -3.97  -3.78  -3.53   3399    1.0\n",
      "log_lik[22]   -3.8  4.5e-3   0.24  -4.37  -3.92  -3.77  -3.64  -3.43   2825    1.0\n",
      "log_lik[23]  -4.06  6.0e-3   0.36  -4.96  -4.24  -3.99  -3.81  -3.55   3618    1.0\n",
      "log_lik[24]  -4.03  5.9e-3   0.34  -4.85  -4.22  -3.97  -3.78  -3.53   3399    1.0\n",
      "log_lik[25]  -3.71  4.1e-3   0.19  -4.14  -3.82   -3.7  -3.58  -3.38   2096    1.0\n",
      "log_lik[26]  -5.83    0.01   0.96  -8.08  -6.38   -5.7  -5.14  -4.33   4136    1.0\n",
      "log_lik[27]  -3.77  4.2e-3   0.22  -4.31  -3.88  -3.74  -3.62  -3.41   2706    1.0\n",
      "log_lik[28]  -4.37  8.6e-3   0.51  -5.62  -4.62  -4.25  -4.01  -3.68   3440    1.0\n",
      "log_lik[29]  -3.96  6.0e-3   0.32  -4.71  -4.13   -3.9  -3.73  -3.47   2914    1.0\n",
      "log_lik[30]  -4.09  6.6e-3   0.39  -5.07  -4.28   -4.0  -3.82  -3.56   3454    1.0\n",
      "lp__        -108.9    0.07    2.5 -114.9 -110.2 -108.5 -107.0 -105.2   1287    1.0\n",
      "\n",
      "Samples were drawn using NUTS at Sat Nov 17 23:10:59 2018.\n",
      "For each parameter, n_eff is a crude measure of effective sample size,\n",
      "and Rhat is the potential scale reduction factor on split chains (at \n",
      "convergence, Rhat=1).\n"
     ]
    }
   ],
   "source": [
    "# Hierarchical\n",
    "\n",
    "fit_hierarchical = sm_factory_hierarchical.sampling(data=factory_hierarchical_dat, n_jobs=-1)\n",
    "mu7_hierarchical=fit_hierarchical.extract(permuted=True)['mu7']\n",
    "ypred6_hierarchical=fit_hierarchical.extract(permuted=True)['ypred6']\n",
    "mu_hierarchical=fit_hierarchical.extract(permuted=True)['mu']\n",
    "log_lik=fit_hierarchical.extract(permuted=True)['log_lik']\n",
    "psis=psisloo(log_lik)\n",
    "print(\"PSIS-LOO value:\", psis[0])\n",
    "#Estimate of the effective number of parameters\n",
    "#lppd (computd log pointwise predictive density) calculation\n",
    "S=np.size(log_lik,0)\n",
    "lppd=sum(np.log([1/S*sum(np.exp(col)) for col in log_lik.T]))\n",
    "#Effective number of parameters formula: p_loocv=lppd-lppd_loocv\n",
    "p_loocv=lppd-psis[0]\n",
    "print(\"p_loo-cv estimated effective number of parameters:\",p_loocv)\n",
    "plt.hist(psis[2],bins=np.linspace(0,1,11))\n",
    "plt.title(\"$\\^{k}$ of PSIS-LOO for the observations with hierarchical model N=4000\")\n",
    "plt.show()\n",
    "\n",
    "summary_hierarchical=fit_hierarchical.summary()\n",
    "summary_df_hierarchical=pd.DataFrame(summary_hierarchical['summary'], \n",
    "                                     columns=summary_hierarchical['summary_colnames'], \n",
    "                                     index=summary_hierarchical['summary_rownames'])\n",
    "\n",
    "#Print info on the fitting and sampling of paramters alpha and beta \n",
    "print(fit_hierarchical)\n",
    "#fit_hierarchical.plot()\n",
    "#plt.show()\n",
    "\n",
    "#plt.hist(mu_hierarchical[:,5],bins=50)\n",
    "#plt.title(\"Posterior mean of machine 6\")\n",
    "#plt.show()\n",
    "#plt.hist(ypred6_hierarchical, bins=50)\n",
    "#plt.title(\"Predictive distribution of quality measurement for machine 6\")\n",
    "#plt.show()\n",
    "#plt.hist(mu7_hierarchical, bins=50)\n",
    "#plt.title(\"Posterior distribution of mean of quality measurement for machine 7\")\n",
    "#plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
